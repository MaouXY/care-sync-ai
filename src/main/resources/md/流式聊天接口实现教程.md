# 流式聊天接口实现教程

## 概述

本教程详细讲解如何实现一个类似ChatGPT的流式聊天接口，使用Spring Boot和SSE(Server-Sent Events)技术，实现AI回复的实时流式传输。

## 技术栈

- **后端框架**: Spring Boot
- **流式通信**: Server-Sent Events (SSE)
- **AI服务**: ArkUtil (封装的AI服务调用工具)
- **数据格式**: OpenAI兼容的JSON格式
- **数据库**: MyBatis Plus

## 接口基本信息

- **接口路径**: `POST /lit-chat/send/stream`
- **请求类型**: POST
- **返回类型**: `MediaType.TEXT_EVENT_STREAM_VALUE` (SSE流式响应)
- **超时时间**: 5分钟 (300000毫秒)

## 请求参数

### LitChatMessageDTO

```java
@Data
@Builder
@Schema(description = "LiteChat消息DTO")
public class LitChatMessageDTO {
    @Schema(description = "讨论书籍")
    private String bookName;      // 讨论的书籍名称
    
    @Schema(description = "会话ID")
    private String sessionId;     // 会话ID（用于关联对话历史）
    
    @Schema(description = "AI伙伴ID")
    private Long AIPartnerId;     // AI伙伴ID（选择不同的AI角色）
    
    @Schema(description = "聊天请求")
    private ChatRequest chatRequest; // 聊天请求内容
}
```

### ChatRequest

```java
// ChatRequest 结构示例
public class ChatRequest {
    private String prompt;  // 用户输入的问题或消息
    // 其他可能的参数...
}
```

## 接口实现详解

### 1. 接口定义

```java
@PostMapping(value = "/send/stream", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
@Operation(summary="发送消息（流式接口）", description = "发送消息，流式返回AI回复")
public SseEmitter sendMessageStream(@RequestBody LitChatMessageDTO litChatMessageDTO) {
    // 实现代码...
}
```

- `produces = MediaType.TEXT_EVENT_STREAM_VALUE`: 指定返回内容类型为SSE流
- `SseEmitter`: Spring提供的SSE响应类型

### 2. 初始化SSE连接

```java
// 创建SseEmitter，设置超时时间为5分钟
SseEmitter sseEmitter = new SseEmitter(300000L);
```

- 创建SSE发射器，设置5分钟超时
- 避免长时间连接占用服务器资源

### 3. 异步处理

```java
// 异步处理，避免阻塞主线程
new Thread(() -> {
    try {
        // 核心业务逻辑
    } catch (Exception e) {
        // 异常处理
    }
}).start();

return sseEmitter;
```

- 使用新线程处理AI调用，不阻塞HTTP请求线程
- 提高服务器并发处理能力
- 立即返回SseEmitter对象，建立连接

### 4. 保存用户消息

```java
// 保存用户消息到数据库
LitChatMessage userMessage = LitChatMessage.builder()
        .sessionId(litChatMessageDTO.getSessionId())
        .role("user")
        .content(litChatMessageDTO.getChatRequest().getPrompt())
        .build();
litChatMessageService.save(userMessage);
```

- 将用户输入保存到数据库
- 记录对话历史，role标记为"user"

### 5. 构建系统提示词

```java
// 获取系统提示词
String systemPrompt = "你是一个专业的文学助手，能够回答用户关于文学的问题。";
// 获取AI合作伙伴
AiPartner aiPartner = aiPartnerService.getById(litChatMessageDTO.getAIPartnerId());
if (aiPartner != null) {
    systemPrompt = aiPartner.getPrompt();
}
// 讨论书籍
if (litChatMessageDTO.getBookName() != null) {
    systemPrompt += " 当前讨论的书籍为：" + litChatMessageDTO.getBookName();
}
```

- 支持动态AI角色切换
- 支持书籍上下文设置
- 增强AI回复的针对性和准确性

### 6. 流式调用AI服务

```java
// 调用ArkUtil的流式方法获取回复
StringBuilder fullResponse = new StringBuilder();

// 订阅流式响应
arkUtil.streamBotChat(litChatMessageDTO.getChatRequest(), systemPrompt)
        .doOnError(throwable -> {
            // 错误处理
        })
        .doFinally(signalType -> {
            // 完成处理
        })
        .subscribe(content -> {
            // 实时处理每个回复片段
        });
```

- 使用响应式编程模型处理流式数据
- `StringBuilder`用于累加完整回复内容
- `doOnError`处理流式过程中的错误
- `doFinally`在流结束时执行清理工作
- `subscribe`处理每个流式数据片段

### 7. 实时数据推送

```java
.subscribe(content -> {
    try {
        if (!content.isEmpty()) {
            // 累加完整回复
            fullResponse.append(content);
            
            // 构造符合OpenAI格式的JSON数据
            Map<String, Object> chatChunk = new HashMap<>();
            chatChunk.put("id", "chatcmpl-" + UUID.randomUUID());
            chatChunk.put("object", "chat.completion.chunk");
            chatChunk.put("created", System.currentTimeMillis());
            chatChunk.put("model", botId);
            
            // 构造choices数组
            Map<String, Object> choice = new HashMap<>();
            choice.put("index", 0);
            
            // 构造delta对象（增量内容）
            Map<String, Object> delta = new HashMap<>();
            delta.put("content", content);
            choice.put("delta", delta);
            choice.put("finish_reason", null);
            
            chatChunk.put("choices", new Object[]{choice});
            
            // 转换为JSON字符串
            String json = objectMapper.writeValueAsString(chatChunk);
            // 推送当前片段到前端，使用标准SSE格式
            sseEmitter.send("data: " + json + "\n\n");
        }
    } catch (JsonProcessingException e) {
        // JSON序列化失败，发送错误信息
        System.err.println("JSON序列化失败: " + e.getMessage());
    } catch (Exception e) {
        // 发送失败，关闭连接
        sseEmitter.completeWithError(e);
    }
});
```

#### 数据格式说明

每个推送的数据包遵循OpenAI的流式接口格式：

```json
{
  "id": "chatcmpl-xxx",
  "object": "chat.completion.chunk", 
  "created": 1700000000,
  "model": "gpt-3.5-turbo",
  "choices": [{
    "index": 0,
    "delta": {
      "content": "当前回复片段"
    },
    "finish_reason": null
  }]
}
```

- `id`: 唯一标识符，使用UUID生成
- `object`: 固定值为"chat.completion.chunk"
- `created`: 时间戳
- `model`: AI模型标识
- `choices`: 包含回复内容的数组
  - `index`: 选择索引，通常为0
  - `delta`: 增量内容对象
    - `content`: 当前片段的文本内容
  - `finish_reason`: 完成原因，流式过程中为null

### 8. 完成处理

```java
.doFinally(signalType -> {
    try {
        // 保存完整回复到数据库
        if (!fullResponse.isEmpty()) {
            LitChatMessage assistantMessage = LitChatMessage.builder()
                    .sessionId(litChatMessageDTO.getSessionId())
                    .role("ai")
                    .content(fullResponse.toString())
                    .build();
            litChatMessageService.save(assistantMessage);
        }
    } catch (Exception e) {
        // 忽略保存错误
    } finally {
        try {
            // 无论是否发生异常，都发送流结束信号
            sseEmitter.send("data: [DONE]\n\n");
            sseEmitter.complete();
        } catch (Exception e) {
            // 忽略发送错误
        }
    }
});
```

- 保存完整的AI回复到数据库
- 发送流结束信号 `[DONE]`
- 关闭SSE连接

### 9. 错误处理

#### AI服务错误处理

```java
.doOnError(throwable -> {
    try {
        sseEmitter.send(SseEmitter.event().name("error").data("AI服务错误: " + throwable.getMessage()));
        sseEmitter.completeWithError(throwable);
    } catch (Exception e) {
        // 忽略发送错误
    }
});
```

#### 通用异常处理

```java
catch (Exception e) {
    try {
        // 构造错误信息的JSON格式
        Map<String, Object> errorChunk = new HashMap<>();
        errorChunk.put("id", "chatcmpl-" + UUID.randomUUID());
        errorChunk.put("object", "chat.completion.chunk");
        errorChunk.put("created", System.currentTimeMillis());
        errorChunk.put("model", "default");
        
        // 构造choices数组
        Map<String, Object> choice = new HashMap<>();
        choice.put("index", 0);
        
        // 构造delta对象
        Map<String, Object> delta = new HashMap<>();
        delta.put("content", "服务错误: " + e.getMessage());
        choice.put("delta", delta);
        choice.put("finish_reason", null);
        
        errorChunk.put("choices", new Object[]{choice});
        
        // 转换为JSON字符串
        String errorJson = objectMapper.writeValueAsString(errorChunk);
        sseEmitter.send("data: " + errorJson + "\n\n");
        sseEmitter.completeWithError(e);
    } catch (JsonProcessingException ex) {
        // JSON序列化失败，直接发送错误信息
        try {
            sseEmitter.send("data: {\"error\":\"服务错误: " + ex.getMessage() + "}\n\n");
        } catch (IOException exc) {
            throw new RuntimeException(exc);
        }
        sseEmitter.completeWithError(ex);
    } catch (Exception ex) {
        // 忽略
    }
}
```

## 前端使用示例

### JavaScript EventSource API

```javascript
// 创建SSE连接
const eventSource = new EventSource('/lit-chat/send/stream', {
    method: 'POST',
    body: JSON.stringify({
        sessionId: 'your-session-id',
        AIPartnerId: 1,
        chatRequest: {
            prompt: '你好，请介绍一下《红楼梦》'
        },
        bookName: '红楼梦'
    }),
    headers: {
        'Content-Type': 'application/json'
    }
});

// 处理流式数据
eventSource.onmessage = function(event) {
    const data = JSON.parse(event.data);
    
    // 检查是否为结束信号
    if (event.data === '[DONE]') {
        console.log('流式响应结束');
        eventSource.close();
        return;
    }
    
    // 处理错误事件
    if (event.type === 'error') {
        console.error('SSE错误:', data);
        return;
    }
    
    // 显示AI回复内容
    if (data.choices && data.choices[0].delta.content) {
        // 逐字显示AI回复
        document.getElementById('response').innerHTML += data.choices[0].delta.content;
    }
};

// 处理连接错误
eventSource.onerror = function(event) {
    console.error('SSE连接错误:', event);
    eventSource.close();
};
```

### 使用Fetch API的替代方案

```javascript
async function streamChat() {
    const response = await fetch('/lit-chat/send/stream', {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'Accept': 'text/event-stream',
        },
        body: JSON.stringify({
            sessionId: 'your-session-id',
            AIPartnerId: 1,
            chatRequest: {
                prompt: '你好，请介绍一下《红楼梦》'
            },
            bookName: '红楼梦'
        })
    });

    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = decoder.decode(value);
        const lines = chunk.split('\n');

        for (const line of lines) {
            if (line.startsWith('data: ')) {
                const data = line.substring(6);
                
                if (data === '[DONE]') {
                    console.log('流式响应结束');
                    return;
                }
                
                try {
                    const parsed = JSON.parse(data);
                    if (parsed.choices && parsed.choices[0].delta.content) {
                        document.getElementById('response').innerHTML += parsed.choices[0].delta.content;
                    }
                } catch (e) {
                    console.error('解析JSON失败:', e);
                }
            }
        }
    }
}
```

## 技术优势

1. **实时性**: 逐字显示，提升用户体验
2. **兼容性**: 遵循OpenAI标准格式，前端易于集成
3. **可扩展性**: 支持多AI角色、书籍上下文
4. **稳定性**: 完善的错误处理和资源清理
5. **性能**: 异步处理，不阻塞服务器线程

## 注意事项

1. **超时设置**: 5分钟超时适合大多数场景，可根据需求调整
2. **连接管理**: 需要前端正确处理连接关闭和重连
3. **数据格式**: 严格遵循SSE标准格式（`data: {json}\n\n`）
4. **资源清理**: 确保异常情况下正确关闭连接
5. **线程管理**: 当前使用简单线程创建，生产环境建议使用线程池

## 性能优化建议

1. **线程池替代直接线程创建**:
   ```java
   @Autowired
   private TaskExecutor taskExecutor;
   
   // 替换 new Thread() 为
   taskExecutor.execute(() -> {
       // 业务逻辑
   });
   ```

2. **连接超时配置**:
   ```java
   // 可根据实际需求调整超时时间
   SseEmitter sseEmitter = new SseEmitter(60000L); // 1分钟
   ```

3. **心跳机制**:
   ```java
   // 定期发送心跳，保持连接活跃
   ScheduledExecutorService heartbeat = Executors.newSingleThreadScheduledExecutor();
   heartbeat.scheduleAtFixedRate(() -> {
       try {
           sseEmitter.send(SseEmitter.event().name("heartbeat").data("ping"));
       } catch (Exception e) {
           heartbeat.shutdown();
       }
   }, 0, 30, TimeUnit.SECONDS);
   ```

## 总结

本教程详细介绍了如何使用Spring Boot和SSE技术实现流式聊天接口。这种实现方式提供了良好的用户体验，使AI回复能够实时显示，同时保持了代码的可维护性和扩展性。通过遵循OpenAI的标准格式，前端可以轻松集成，实现类似ChatGPT的交互体验。